{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculating my polygenic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from typing import List, Optional, Tuple\n",
    "import pysam\n",
    "import rsidx\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display\n",
    "from search_your_dna.pgscatalog import read_or_download_pgs_scoring_file, PGS_METHOD_MAPPING_TO_METHOD_CATEGORIES, \\\n",
    "    MethodCategories\n",
    "from search_your_dna.util import read_raw_zipped_polygenic_score_file\n",
    "\n",
    "file_my_vcf = \"data/GFX0237425.GRCh38.p7.annotated.hg38_multianno.updated.vcf.gz\"\n",
    "file_my_vcf_rsidx = \"data/GFX0237425.GRCh38.p7.annotated.hg38_multianno.updated.vcf.rsidx\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def search_for_rsids(rsids: List[str]):\n",
    "    with sqlite3.connect(file_my_vcf_rsidx) as db:\n",
    "        return list(rsidx.search.search(rsids, db, file_my_vcf))\n",
    "\n",
    "rsids = []\n",
    "search_for_rsids(rsids)\n",
    "\n",
    "def to_gene_dosage_df(variance_str: str):\n",
    "    gene_dosages = []\n",
    "    for v in variance_str:\n",
    "        chrom, pos, rsid, ref, alt, qual, filter, info, format, _ = tuple(v.split())\n",
    "        gene_dosage = int(info[info.find(\"AC\") + 3:info.find(\"AC\") + 4])\n",
    "        gene_dosages.append({\"rsid\": rsid, \"gene_dosage\": gene_dosage})\n",
    "    res = pd.DataFrame(gene_dosages)\n",
    "    res[\"gene_dosage\"] = pd.to_numeric(res[\"gene_dosage\"])\n",
    "    return res\n",
    "\n",
    "\n",
    "def clean_rsids(rsids: pd.Series, pgs_name: str) -> List[str]:\n",
    "    if np.any(rsids.isna()):\n",
    "        print(f\"PGS {pgs_name} has {np.count_nonzero(rsids.isna())} missing rsids\")\n",
    "        rsids = rsids.dropna()\n",
    "    start_with_rs = rsids.str.startswith(\"rs\")\n",
    "    if np.any(~start_with_rs):\n",
    "        print(f\"PGS {pgs_name} has {np.count_nonzero(~start_with_rs)} non rsid values\")\n",
    "        rsids = rsids[start_with_rs]\n",
    "    values_with_commas_or_underscores = rsids.str.contains(\",\") | rsids.str.contains(\"_\")\n",
    "    if np.any(values_with_commas_or_underscores):\n",
    "        print(f\"PGS {pgs_name} has {np.count_nonzero(values_with_commas_or_underscores)} rsids containing multiple values\")\n",
    "        rsids = rsids[~values_with_commas_or_underscores]\n",
    "    return rsids.to_list()\n",
    "\n",
    "def calc_polygenic_score(max_pgs_alleles: Optional[int] = None, pgs_df: Optional[pd.DataFrame] = None, pgs_file: Optional[str] = None) -> Tuple[float, pd.DataFrame]:\n",
    "    if pgs_df is None:\n",
    "        pgs_df = read_raw_zipped_polygenic_score_file(pgs_file)\n",
    "    if max_pgs_alleles is not None and len(pgs_df.index) > max_pgs_alleles:\n",
    "        raise Exception(f\"Too many snps for {pgs_file}. Total {len(pgs_df.index)}\")\n",
    "    pgs_rsids = clean_rsids(pgs_df['rsid'], Path(pgs_file).stem)\n",
    "    my_variance = search_for_rsids(pgs_rsids)\n",
    "    gene_dosage_df = to_gene_dosage_df(my_variance)\n",
    "    merged_df = pgs_df.merge(gene_dosage_df, on=\"rsid\", how=\"outer\")\n",
    "    merged_df[\"gene_dosage\"] = merged_df[\"gene_dosage\"].fillna(0)\n",
    "    merged_df[\"effect\"] = merged_df[\"gene_dosage\"] * merged_df[\"effect_weight\"]\n",
    "    return merged_df[\"effect\"].sum(), merged_df\n",
    "\n",
    "\n",
    "pgs, pgs_df = calc_polygenic_score(max_pgs_alleles=1000, pgs_file=\"data/pgs/PGS000034.txt.gz\")\n",
    "pgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors = {}\n",
    "all_pgs_scores = pd.DataFrame(columns=[\"file\", \"score\"])\n",
    "for pgs_file in tqdm(sorted(glob(\"data/pgs/PGS00*.txt.gz\"))):\n",
    "    try:\n",
    "        pgs, _ = calc_polygenic_score(max_pgs_alleles=200, pgs_file=pgs_file)\n",
    "        all_pgs_scores = all_pgs_scores.append({\"file\": pgs_file, \"score\": pgs}, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        errors[pgs_file] = [str(e), ''.join(traceback.format_exception(None, e, e.__traceback__))]\n",
    "all_pgs_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_pgs_scores[\"pgs_id\"] = all_pgs_scores[\"file\"].apply(lambda v: Path(v).stem[:-4])\n",
    "all_pgs_scores = all_pgs_scores[[\"pgs_id\", \"score\", \"file\"]]\n",
    "all_pgs_scores.to_csv(\"data/pgs_results.csv\", index=None, sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add PGS metadata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pgs_score_dfs = []\n",
    "method = pd.Series(dtype=str)\n",
    "method_parsed = pd.Series(dtype=str)\n",
    "trait = pd.Series(dtype=str)\n",
    "for _, pgs_row in tqdm(all_pgs_scores.iterrows()):\n",
    "    metadata_json, _ = read_or_download_pgs_scoring_file(pgs_row[\"pgs_id\"])\n",
    "    method = method.append(pd.Series([metadata_json[\"method_name\"]]))\n",
    "    method_parsed = method_parsed.append(pd.Series([PGS_METHOD_MAPPING_TO_METHOD_CATEGORIES.get(metadata_json[\"method_name\"])]))\n",
    "    trait = trait.append(pd.Series([metadata_json[\"trait_reported\"]]))\n",
    "\n",
    "all_pgs_scores_with_metadata = all_pgs_scores.copy(deep=True)\n",
    "method.index = all_pgs_scores.index\n",
    "method_parsed.index = all_pgs_scores.index\n",
    "trait.index = all_pgs_scores.index\n",
    "all_pgs_scores_with_metadata[\"method\"] = method\n",
    "all_pgs_scores_with_metadata[\"method_parsed\"] = method_parsed\n",
    "all_pgs_scores_with_metadata[\"trait\"] = trait\n",
    "all_pgs_scores_with_metadata = all_pgs_scores_with_metadata[[\"pgs_id\", \"trait\", \"score\", \"method_parsed\"]]\n",
    "all_pgs_scores_with_metadata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}